{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "from IPython import display\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "\n",
    "\"\"\" processed_dir = [\"0001 - bleach\", \"0002 - one piece\",\"0003 - marvel\",\"0004 - DC\", \"0005 - Love\", \"0006 - soma\", \n",
    "                        \"0007 - ishoujo\", \"0008 - vagabond\", \"0009 - vampire r\", \"0010 - gintama\", \"0011 - gantz\",\n",
    "                         \"0012 - chainsaw\", \"0013 - death note\", \"0014 - batman\" ] \"\"\"\n",
    "\"\"\" processed_dir = [\"\"] \"\"\"\n",
    "\n",
    "processed_dir = [\"0001 - bleach\", \"0002 - one piece\",\"0003 - marvel\",\"0004 - DC\", \"0005 - Love\", \"0006 - soma\", \n",
    "                        \"0007 - ishoujo\", \"0008 - vagabond\", \"0009 - vampire r\",\"0010 - gintama\", \"0011 - gantz\", \"0012 - chainsaw\",\n",
    "                         \"0013 - death note\", \"0014 - batman\" ]\n",
    "\n",
    "\n",
    "\n",
    "data_directory = 'D:\\\\Deletar\\\\pictures'\n",
    "test_directory = 'G:\\\\Deletar\\\\pictures_conv'\n",
    "DELTA_HUE = -1 # -1 ~ 1\n",
    "DELTA_SAT = 0 # 0 < inf\n",
    "DELTA_BRIGHTNESS = 0.5 # -1 ~ 1\n",
    "tf.random.set_seed(42) \n",
    "SIZE = [512,512]\n",
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 104\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[39mprint\u001b[39m(cont2)\n\u001b[0;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m images\n\u001b[1;32m--> 104\u001b[0m X_test \u001b[39m=\u001b[39m get_bw_from_folder(data_directory)\n",
      "Cell \u001b[1;32mIn[4], line 88\u001b[0m, in \u001b[0;36mget_bw_from_folder\u001b[1;34m(folder)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     img \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdata_directory\u001b[39m}\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m{\u001b[39;00mfolder\u001b[39m}\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m,filename))                    \n\u001b[1;32m---> 88\u001b[0m     img \u001b[39m=\u001b[39m resize_image(img)     \n\u001b[0;32m     89\u001b[0m     \u001b[39m\"\"\" img2 = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY) # Input IMG is RGB\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m    img2 = cv2.merge([img2,img2,img2]) \"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\"\" plt.imshow(img2) \"\"\"\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36mresize_image\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresize_image\u001b[39m(data):\n\u001b[1;32m----> 2\u001b[0m     resized_img \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mresize(\n\u001b[0;32m      3\u001b[0m     images\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m      4\u001b[0m     size\u001b[39m=\u001b[39;49mSIZE,\n\u001b[0;32m      5\u001b[0m     method\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mResizeMethod\u001b[39m.\u001b[39;49mBILINEAR,\n\u001b[0;32m      6\u001b[0m     preserve_aspect_ratio\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m     antialias\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,    \n\u001b[0;32m      8\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m     )    \n\u001b[0;32m     10\u001b[0m     \u001b[39mreturn\u001b[39;00m resized_img\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1717\u001b[0m, in \u001b[0;36mresize_images_v2\u001b[1;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[0;32m   1714\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mResize method is not implemented: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(method))\n\u001b[1;32m-> 1717\u001b[0m \u001b[39mreturn\u001b[39;00m _resize_images_common(\n\u001b[0;32m   1718\u001b[0m     images,\n\u001b[0;32m   1719\u001b[0m     resize_fn,\n\u001b[0;32m   1720\u001b[0m     size,\n\u001b[0;32m   1721\u001b[0m     preserve_aspect_ratio\u001b[39m=\u001b[39;49mpreserve_aspect_ratio,\n\u001b[0;32m   1722\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1723\u001b[0m     skip_resize_if_same\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\image_ops_impl.py:1394\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[1;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[39mif\u001b[39;00m images\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mndims \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m   1393\u001b[0m   is_batch \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1394\u001b[0m   images \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49mexpand_dims(images, \u001b[39m0\u001b[39;49m)\n\u001b[0;32m   1395\u001b[0m \u001b[39melif\u001b[39;00m images\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mndims \u001b[39m!=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m   1396\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mimages\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m must have either 3 or 4 dimensions.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:549\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    542\u001b[0m       logging\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    543\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mFrom \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: calling \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (from \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) with \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is deprecated and will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    544\u001b[0m           \u001b[39m'\u001b[39m\u001b[39mbe removed \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstructions for updating:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m           \u001b[39m'\u001b[39m\u001b[39min a future version\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m date \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mafter \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m date),\n\u001b[0;32m    548\u001b[0m           instructions)\n\u001b[1;32m--> 549\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:367\u001b[0m, in \u001b[0;36mexpand_dims\u001b[1;34m(input, axis, name, dim)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    366\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mMust specify an axis argument to tf.expand_dims()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 367\u001b[0m \u001b[39mreturn\u001b[39;00m expand_dims_v2(\u001b[39minput\u001b[39;49m, axis, name)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[39m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[39mreturn\u001b[39;00m target(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[39m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:437\u001b[0m, in \u001b[0;36mexpand_dims_v2\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mexpand_dims\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    371\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[0;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexpand_dims_v2\u001b[39m(\u001b[39minput\u001b[39m, axis, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    373\u001b[0m   \u001b[39m\"\"\"Returns a tensor with a length 1 axis inserted at index `axis`.\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \n\u001b[0;32m    375\u001b[0m \u001b[39m  Given a tensor `input`, this operation inserts a dimension of length 1 at the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[39m    InvalidArgumentError: If `axis` is out of range `[-(D+1), D]`.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 437\u001b[0m   \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mexpand_dims(\u001b[39minput\u001b[39;49m, axis, name)\n",
      "File \u001b[1;32mc:\\Users\\Matheus\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:2284\u001b[0m, in \u001b[0;36mexpand_dims\u001b[1;34m(input, axis, name)\u001b[0m\n\u001b[0;32m   2282\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   2283\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2284\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   2285\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mExpandDims\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, axis)\n\u001b[0;32m   2286\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   2287\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def resize_image(data):\n",
    "    resized_img = tf.image.resize(\n",
    "    images=data,\n",
    "    size=SIZE,\n",
    "    method=tf.image.ResizeMethod.BILINEAR,\n",
    "    preserve_aspect_ratio=False,\n",
    "    antialias=True,    \n",
    "    name=None\n",
    "    )    \n",
    "    return resized_img\n",
    "\n",
    "def adjust_hue_sat_lum(data):\n",
    "    mod_img = tf.image.adjust_hue(\n",
    "        data, DELTA_HUE\n",
    "    )\n",
    "    mod_img = tf.image.adjust_saturation(\n",
    "        mod_img, DELTA_SAT\n",
    "    )\n",
    "    mod_img = tf.image.adjust_brightness(\n",
    "        mod_img, DELTA_BRIGHTNESS\n",
    "    ) \n",
    "    return mod_img\n",
    "    \n",
    "\n",
    "def save_f(img,filename,contI):\n",
    "    dir_save = \"\"\n",
    "    if (contI % 5 != 0):\n",
    "        dir_save = f\"{test_directory}\\\\train\\\\{filename}.jpg\"\n",
    "    else:\n",
    "        dir_save = f\"{test_directory}\\\\test\\\\{filename}.jpg\"\n",
    "    tf.keras.preprocessing.image.save_img(dir_save, img)\n",
    "    \n",
    "#if (os.path.exists(os.path.join(f\"{data_directory}\\\\{folder}\",filename+\".jpg\"))):    \n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    cont = 0\n",
    "    cont2 = 0    \n",
    "    for folder in os.listdir(folder):\n",
    "        if not folder in processed_dir:\n",
    "            for filename in os.listdir(os.path.join(f\"{data_directory}\\\\{folder}\")):        \n",
    "                cont2 = cont2 + 1\n",
    "                if (not os.path.exists(os.path.join(f\"{data_directory}\\\\{folder}\\\\\",filename+\".jpg\"))):                        \n",
    "                    try:\n",
    "                        img1 = resize_image(plt.imread(os.path.join(f\"{data_directory}\\\\{folder}\\\\\",filename)))\n",
    "                        img2 =  tf.image.rgb_to_grayscale(img1)\n",
    "                        img2 = np.concatenate((img2/3,img2/3,img2/3),axis=-1)\n",
    "                        img_merged = tf.concat([img1, img2], 1)\n",
    "                        if img_merged is not None:\n",
    "                            save_f(img_merged,filename,cont2)\n",
    "                    except:\n",
    "                            cont = cont + 1\n",
    "                            print(f\"Error in {cont}\")\n",
    "                print(cont2)\n",
    "    return images\n",
    "\n",
    "\"\"\" X_test = load_images_from_folder(data_directory) # join two images \"\"\"\n",
    "\n",
    "\n",
    "def save_bw_cl(img,filename,contI, img2):\n",
    "    dir_save = \"\"    \n",
    "    if (contI % 10 != 0):\n",
    "        dir_save = f\"{test_directory}\\\\train_new\\\\color\\\\{filename}.jpg\"\n",
    "        dir_save2 = f\"{test_directory}\\\\train_new\\\\bw\\\\{filename}.jpg\"\n",
    "    else:\n",
    "        dir_save = f\"{test_directory}\\\\test_new\\\\color\\\\{filename}.jpg\"\n",
    "        dir_save2 = f\"{test_directory}\\\\test_new\\\\bw\\\\{filename}.jpg\"\n",
    "    isExist = os.path.exists(dir_save)\n",
    "    isExist2 = os.path.exists(dir_save2)\n",
    "    \"\"\" if not isExist:\n",
    "        os.makedirs(path) \"\"\"\n",
    "    tf.keras.preprocessing.image.save_img(dir_save, img)\n",
    "    tf.keras.preprocessing.image.save_img(dir_save2, img2)\n",
    "\n",
    "def get_bw_from_folder(folder):\n",
    "    images = []\n",
    "    cont = 0\n",
    "    cont2 = 0    \n",
    "    for folder in os.listdir(folder):\n",
    "        if not folder in processed_dir:\n",
    "            for filename in os.listdir(os.path.join(f\"{data_directory}\\\\{folder}\")):        \n",
    "                cont2 = cont2 + 1\n",
    "                \n",
    "                \"\"\" if (not os.path.exists(os.path.join(f\"{data_directory}\\\\{folder}\\\\\",filename))): \"\"\"\n",
    "                               \n",
    "                try:\n",
    "                    img = plt.imread(os.path.join(f\"{data_directory}\\\\{folder}\\\\\",filename))                    \n",
    "                    img = resize_image(img)     \n",
    "                    \"\"\" img2 = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2GRAY) # Input IMG is RGB\n",
    "                    img2 = cv2.merge([img2,img2,img2]) \"\"\"\n",
    "                    \"\"\" plt.imshow(img2) \"\"\"\n",
    "                    img2 = adjust_hue_sat_lum(img)\n",
    "                    if img is not None:\n",
    "                        save_bw_cl(img,filename,cont2, img2)\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    cont = cont + 1                            \n",
    "                    print(e)\n",
    "                \n",
    "                print(cont2)\n",
    "                \n",
    "    return images\n",
    "\n",
    "X_test = get_bw_from_folder(data_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2920df7931abb429103ba85be4f143bf64cc29fe08904a577bcc33052e2165b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
