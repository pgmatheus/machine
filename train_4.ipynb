{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"pizza_steak.zip\", \n",
    "    origin=\"https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\", \n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "current_directory = os.path.join(os.path.dirname(dataset))\n",
    "data_directory = os.path.join(current_directory, \"pizza_steak\")\n",
    "\n",
    "\"\"\" data_dir = pathlib.Path(dataset) \"\"\"\n",
    "\n",
    "tf.random.set_seed(42) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' img = mpimg.imread(\"C:\\\\Users\\\\Matheus\\\\.keras\\\\datasets\\\\pizza_steak\\\\test\\\\pizza\\\\204151.jpg\")\\nplt.imshow(img)  '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# img plot\n",
    "\"\"\" img = mpimg.imread(\"C:\\\\Users\\\\Matheus\\\\.keras\\\\datasets\\\\pizza_steak\\\\test\\\\pizza\\\\204151.jpg\")\n",
    "plt.imshow(img)  \"\"\"\n",
    "# img plot end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1f893e05690>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = data_directory + \"\\\\train\"\n",
    "test_dir =  data_directory + \"\\\\test\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.3,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    directory=train_dir,\n",
    "    batch_size=32,\n",
    "    target_size=(224,224),\n",
    "    class_mode=\"binary\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "\"\"\" valid_datagen = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    rotation_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.3,\n",
    "    horizontal_flip=True\n",
    "    ) \"\"\"\n",
    "\n",
    "\n",
    "test_data = valid_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    batch_size=32,\n",
    "    target_size=(224,224),\n",
    "    class_mode=\"binary\",\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "47/47 [==============================] - 43s 892ms/step - loss: 0.6126 - accuracy: 0.6493 - val_loss: 0.4225 - val_accuracy: 0.8080\n",
      "Epoch 2/5\n",
      "47/47 [==============================] - 40s 857ms/step - loss: 0.5104 - accuracy: 0.7547 - val_loss: 0.3885 - val_accuracy: 0.8520\n",
      "Epoch 3/5\n",
      "47/47 [==============================] - 40s 844ms/step - loss: 0.4964 - accuracy: 0.7567 - val_loss: 0.4918 - val_accuracy: 0.7740\n",
      "Epoch 4/5\n",
      "47/47 [==============================] - 40s 842ms/step - loss: 0.4971 - accuracy: 0.7573 - val_loss: 0.3677 - val_accuracy: 0.8500\n",
      "Epoch 5/5\n",
      "47/47 [==============================] - 41s 859ms/step - loss: 0.4803 - accuracy: 0.7820 - val_loss: 0.4150 - val_accuracy: 0.8320\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(\n",
    "        filters=10,\n",
    "        kernel_size=3,\n",
    "        activation=\"relu\",\n",
    "        input_shape=(224,224,3)\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(\n",
    "        pool_size=2,\n",
    "        padding=\"valid\"\n",
    "    ),\n",
    "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
    "    tf.keras.layers.Conv2D(10,3,activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "]) \n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=\"Adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(train_data, epochs=5, steps_per_epoch=len(train_data), validation_data= test_data, validation_steps=len(test_data) )\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
